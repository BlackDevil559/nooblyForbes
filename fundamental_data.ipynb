{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stock_symbols = [\n",
    "    \"RELIANCE.NS\", \"TCS.NS\", \"HDFCBANK.NS\", \"BHARTIARTL.NS\", \"ICICIBANK.NS\", \n",
    "    \"INFY.NS\", \"HINDUNILVR.NS\", \"SBIN.NS\", \"ITC.NS\", \"LICI.NS\"\n",
    "]\n",
    "\n",
    "# stock_symbols = [\"HDFCBANK.NS\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=3*365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book Value of TCS:  605.573\n",
      "605.573\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "book_value_tcs = yf.Ticker(stock_symbols[0]).info[\"bookValue\"]\n",
    "print(\"Book Value of TCS: \", book_value_tcs)\n",
    "# Print the book value information in a formatted way\n",
    "print(json.dumps(book_value_tcs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfc_book_value = [576.01,500.26,432.36,369.54]\n",
    "hdfc_eps = [80.05, 79.05, 66.65, 56.44]\n",
    "reliance_book_value = [585.80, 528.54, 575.80, 511.71]\n",
    "reliance_eps = [51.45,49.29,44.87,38.11]\n",
    "tcs_book_value = [198.29,203.28,209.27,199.67]\n",
    "tcs_eps = [120.33,106.85,104.34,83.68]\n",
    "icici_book_value = [358.32,301.66,256.96,223.34]\n",
    "icici_eps = [63.02,48.74,36.14,26.58]\n",
    "bharti_book_value = [142.20, 136.41, 118.88, 105.16]\n",
    "bharti_eps = [12.98, 14.71, 7.61, -26.95]\n",
    "infy_book_value = [193.40, 161.20, 163.34, 167.04]\n",
    "infy_eps = [65.62,56.09,50.49,42.37]\n",
    "hindunilvr_book_value = [216.91, 213.71, 207.49, 201.83]\n",
    "hindunilvr_eps = [43.04,42.39,37.52,33.85]\n",
    "sbin_book_value = [391.83,335.98,287.64,258.05]\n",
    "sbin_eps = [68.44, 56.29, 35.49, 22.87]\n",
    "itc_book_value = [57.45, 53.79, 48.76, 46.55]\n",
    "itc_eps = [16.36, 15.09, 12.22, 10.59]\n",
    "lici_book_value = [131.37,73.59,17.96,10.91]\n",
    "lici_eps = [64.69,56.91,6.52,4.70]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for RELIANCE.NS saved to RELIANCE.NS_financial_data.csv\n",
      "Data for TCS.NS saved to TCS.NS_financial_data.csv\n",
      "Data for HDFCBANK.NS saved to HDFCBANK.NS_financial_data.csv\n",
      "Data for BHARTIARTL.NS saved to BHARTIARTL.NS_financial_data.csv\n",
      "Data for ICICIBANK.NS saved to ICICIBANK.NS_financial_data.csv\n",
      "Data for INFY.NS saved to INFY.NS_financial_data.csv\n",
      "Data for HINDUNILVR.NS saved to HINDUNILVR.NS_financial_data.csv\n",
      "Data for SBIN.NS saved to SBIN.NS_financial_data.csv\n",
      "Data for ITC.NS saved to ITC.NS_financial_data.csv\n",
      "Data for LICI.NS saved to LICI.NS_financial_data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a dictionary to map stock symbols to their respective EPS and Book Value lists\n",
    "eps_book_value_data = {\n",
    "    \"HDFCBANK.NS\": (hdfc_eps, hdfc_book_value),\n",
    "    \"RELIANCE.NS\": (reliance_eps, reliance_book_value),\n",
    "    \"TCS.NS\": (tcs_eps, tcs_book_value),\n",
    "    \"ICICIBANK.NS\": (icici_eps, icici_book_value),\n",
    "    \"BHARTIARTL.NS\": (bharti_eps, bharti_book_value),\n",
    "    \"INFY.NS\": (infy_eps, infy_book_value),\n",
    "    \"HINDUNILVR.NS\": (hindunilvr_eps, hindunilvr_book_value),\n",
    "    \"SBIN.NS\": (sbin_eps, sbin_book_value),\n",
    "    \"ITC.NS\": (itc_eps, itc_book_value),\n",
    "    \"LICI.NS\": (lici_eps, lici_book_value)\n",
    "}\n",
    "\n",
    "def fetch_stock_data(symbol):\n",
    "    # Fetch historical data\n",
    "    stock = yf.Ticker(symbol)\n",
    "    data = stock.history(start=start_date.strftime('%Y-%m-%d'), end=end_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "    # Add additional fields\n",
    "    data['Symbol'] = symbol\n",
    "\n",
    "    # Get the EPS and Book Value lists for the symbol\n",
    "    eps_list, book_value_list = eps_book_value_data.get(symbol, ([], []))\n",
    "\n",
    "    # Determine the nearest EPS and Book Value based on the date\n",
    "    data['EPS'] = data.index.map(lambda date: eps_list[0] if date.year == 2024 else \n",
    "                                    eps_list[1] if date.year == 2023 else \n",
    "                                    eps_list[2] if date.year == 2022 else \n",
    "                                    eps_list[3] if date.year == 2021 else None)\n",
    "    data['Book Value'] = data.index.map(lambda date: book_value_list[0] if date.year == 2024 else \n",
    "                                        book_value_list[1] if date.year == 2023 else \n",
    "                                        book_value_list[2] if date.year == 2022 else \n",
    "                                        book_value_list[3] if date.year == 2021 else None)\n",
    "\n",
    "    # Calculate P/E and P/B ratios if EPS and Book Value are available\n",
    "    data['P/E Ratio'] = data['Close'] / data['EPS']\n",
    "    data['P/B Ratio'] = data['Close'] / data['Book Value']\n",
    "\n",
    "    # Select and rename columns\n",
    "    data = data[['Symbol', 'Open', 'High', 'Low', 'Close', 'Volume', 'P/E Ratio', 'P/B Ratio']]\n",
    "    data.columns = ['Symbol', 'Opening Price', 'Highest Price', 'Lowest Price', 'Closing Price', 'Volume of Trade', 'P/E Ratio', 'P/B Ratio']\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_filename = f\"{symbol}_financial_data.csv\"\n",
    "    data.to_csv(csv_filename)\n",
    "    print(f\"Data for {symbol} saved to {csv_filename}\")\n",
    "\n",
    "# Fetch data for each stock symbol\n",
    "for symbol in stock_symbols:\n",
    "    fetch_stock_data(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-11-11 00:00:00+05:30</th>\n",
       "      <td>1152.658008</td>\n",
       "      <td>1166.475961</td>\n",
       "      <td>1150.615905</td>\n",
       "      <td>1159.238037</td>\n",
       "      <td>10722478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-12 00:00:00+05:30</th>\n",
       "      <td>1163.027167</td>\n",
       "      <td>1179.295691</td>\n",
       "      <td>1160.349735</td>\n",
       "      <td>1176.731689</td>\n",
       "      <td>8712341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-15 00:00:00+05:30</th>\n",
       "      <td>1179.862731</td>\n",
       "      <td>1180.861156</td>\n",
       "      <td>1166.248954</td>\n",
       "      <td>1169.788574</td>\n",
       "      <td>4803269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-16 00:00:00+05:30</th>\n",
       "      <td>1167.179255</td>\n",
       "      <td>1168.517971</td>\n",
       "      <td>1132.214564</td>\n",
       "      <td>1142.606445</td>\n",
       "      <td>11337581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-17 00:00:00+05:30</th>\n",
       "      <td>1134.006904</td>\n",
       "      <td>1134.006904</td>\n",
       "      <td>1116.785449</td>\n",
       "      <td>1118.146851</td>\n",
       "      <td>10202029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Date                                                                            \n",
       "2021-11-11 00:00:00+05:30  1152.658008  1166.475961  1150.615905  1159.238037   \n",
       "2021-11-12 00:00:00+05:30  1163.027167  1179.295691  1160.349735  1176.731689   \n",
       "2021-11-15 00:00:00+05:30  1179.862731  1180.861156  1166.248954  1169.788574   \n",
       "2021-11-16 00:00:00+05:30  1167.179255  1168.517971  1132.214564  1142.606445   \n",
       "2021-11-17 00:00:00+05:30  1134.006904  1134.006904  1116.785449  1118.146851   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  \n",
       "Date                                                          \n",
       "2021-11-11 00:00:00+05:30  10722478        0.0           0.0  \n",
       "2021-11-12 00:00:00+05:30   8712341        0.0           0.0  \n",
       "2021-11-15 00:00:00+05:30   4803269        0.0           0.0  \n",
       "2021-11-16 00:00:00+05:30  11337581        0.0           0.0  \n",
       "2021-11-17 00:00:00+05:30  10202029        0.0           0.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock = yf.Ticker(\"RELIANCE.NS\")\n",
    "data = stock.history(start=start_date.strftime('%Y-%m-%d'), end=end_date.strftime('%Y-%m-%d'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting eodhd\n",
      "  Downloading eodhd-1.0.31-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: websockets>=11.0.3 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from eodhd) (13.0.1)\n",
      "Collecting websocket-client>=1.6.3\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.8/58.8 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from eodhd) (2.32.3)\n",
      "Requirement already satisfied: rich>=13.5.2 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from eodhd) (13.8.0)\n",
      "Requirement already satisfied: pandas>=2.1.0 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from eodhd) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.25.2 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from eodhd) (2.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.7.2 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from eodhd) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from matplotlib>=3.7.2->eodhd) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from matplotlib>=3.7.2->eodhd) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from matplotlib>=3.7.2->eodhd) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from matplotlib>=3.7.2->eodhd) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from matplotlib>=3.7.2->eodhd) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from matplotlib>=3.7.2->eodhd) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from matplotlib>=3.7.2->eodhd) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from matplotlib>=3.7.2->eodhd) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from pandas>=2.1.0->eodhd) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from pandas>=2.1.0->eodhd) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from requests>=2.31.0->eodhd) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from requests>=2.31.0->eodhd) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from requests>=2.31.0->eodhd) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from requests>=2.31.0->eodhd) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from rich>=13.5.2->eodhd) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from rich>=13.5.2->eodhd) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13.5.2->eodhd) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sattu\\desktop\\projects\\nooblyforbes\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.7.2->eodhd) (1.16.0)\n",
      "Installing collected packages: websocket-client, eodhd\n",
      "Successfully installed eodhd-1.0.31 websocket-client-1.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install eodhd -U\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'warning': 'Data is limited by one year as you have free subscription'}]\n"
     ]
    }
   ],
   "source": [
    "from eodhd import APIClient\n",
    "import pandas as pd\n",
    "api = APIClient(\"673116f7318a55.21466143\")\n",
    "resp = api.get_eod_historical_stock_market_data(symbol = 'AAPL.MX', period='d', from_date = '2023-01-01', to_date = '2023-01-15', order='a')\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "API_KEY = W4LAI7Dz9X6Aucq2jg7rolLqctfHqmZJ\n",
    "STOCK_NAMES = [\n",
    "    \"RELIANCE.NS\", \"TCS.NS\", \"HDFCBANK.NS\", \"BHARTIARTL.NS\", \"ICICIBANK.NS\", \n",
    "    \"INFY.NS\", \"HINDUNILVR.NS\", \"SBIN.NS\", \"ITC.NS\", \"LICI.NS\"\n",
    "]\n",
    "def fetch_quarterly_eps_and_book_value(symbol):\n",
    "    # Fetch quarterly EPS and book value\n",
    "    url = f'https://financialmodelingprep.com/api/v3/income-statement/{symbol}?period=quarter&limit=1&apikey={API_KEY}'\n",
    "    income_data = requests.get(url).json()\n",
    "    \n",
    "    url = f'https://financialmodelingprep.com/api/v3/balance-sheet-statement/{symbol}?period=quarter&limit=1&apikey={API_KEY}'\n",
    "    balance_data = requests.get(url).json()\n",
    "    \n",
    "    latest_eps = income_data[0][\"eps\"] if income_data else None\n",
    "    latest_book_value = balance_data[0][\"bookValuePerShare\"] if balance_data else None\n",
    "    \n",
    "    return latest_eps, latest_book_value\n",
    "\n",
    "# Fetch quarterly EPS and book value for each stock symbol\n",
    "eps_values = []\n",
    "book_values = []\n",
    "for symbol in stock_symbols:\n",
    "    eps, book_value = fetch_quarterly_eps_and_book_value(symbol)\n",
    "    eps_values.append(eps)\n",
    "    book_values.append(book_value)\n",
    "\n",
    "# Update P/E and P/B ratios in the DataFrame\n",
    "data['EPS'] = eps_values\n",
    "data['Book Value'] = book_values\n",
    "data['P/E Ratio'] = data['Close'] / data['EPS']\n",
    "data['P/B Ratio'] = data['Close'] / data['Book Value']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Error Message': 'Free plan is limited to US stocks only please visit our subscription page to upgrade your plan at https://site.financialmodelingprep.com/developer/docs/pricing'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = f'https://financialmodelingprep.com/api/v3/income-statement/TCS.NS?period=anuual&limit=3&apikey=W4LAI7Dz9X6Aucq2jg7rolLqctfHqmZJ'\n",
    "income_data = requests.get(url).json()\n",
    "print(income_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import pandas as pd\n",
    "\n",
    "uri = \"s3://desiquant/data/news/LICHSGFIN.parquet.gz\"\n",
    "\n",
    "s3_params = {\n",
    "\"endpoint_url\": \"https://cbabd13f6c54798a9ec05df5b8070a6e.r2.cloudflarestorage.com\",\n",
    "\"key\": \"5c8ea9c516abfc78987bc98c70d2868a\", # FREE credentials for public access!\n",
    "\"secret\": \"0cf64f9f0b64f6008cf5efe1529c6772daa7d7d0822f5db42a7c6a1e41b3cadf\", # FREE credentials for public access!\n",
    "\"client_kwargs\": {\n",
    "    \"region_name\": \"auto\"\n",
    "    },\n",
    "}\n",
    "\n",
    "df = pd.read_parquet(uri, storage_options=s3_params)\n",
    "df.to_csv(f\"LICHSGFIN.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "desiquant/data/news/LICI.parquet.gz",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m symbol_without_ns \u001b[38;5;241m=\u001b[39m symbol\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.NS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3://desiquant/data/news/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol_without_ns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms3_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol_without_ns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sattu\\Desktop\\Projects\\nooblyForbes\\venv\\Lib\\site-packages\\pandas\\io\\parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sattu\\Desktop\\Projects\\nooblyForbes\\venv\\Lib\\site-packages\\pandas\\io\\parquet.py:274\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[0;32m    268\u001b[0m     path,\n\u001b[0;32m    269\u001b[0m     filesystem,\n\u001b[0;32m    270\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    271\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    272\u001b[0m )\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\sattu\\Desktop\\Projects\\nooblyForbes\\venv\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1793\u001b[0m, in \u001b[0;36mread_table\u001b[1;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[0m\n\u001b[0;32m   1787\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1788\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_legacy_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated as of pyarrow 15.0.0 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1789\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand will be removed in a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1790\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m   1792\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1793\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mParquetDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1794\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1795\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1798\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1799\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_dictionary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_dictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1800\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1801\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1802\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1803\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpre_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1805\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecryption_properties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecryption_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1806\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1808\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpage_checksum_verification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage_checksum_verification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1809\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# fall back on ParquetFile for simple cases when pyarrow.dataset\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# module is not available\u001b[39;00m\n\u001b[0;32m   1813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sattu\\Desktop\\Projects\\nooblyForbes\\venv\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1371\u001b[0m, in \u001b[0;36mParquetDataset.__init__\u001b[1;34m(self, path_or_paths, filesystem, schema, filters, read_dictionary, memory_map, buffer_size, partitioning, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, use_legacy_dataset)\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m partitioning \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhive\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1368\u001b[0m     partitioning \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mHivePartitioning\u001b[38;5;241m.\u001b[39mdiscover(\n\u001b[0;32m   1369\u001b[0m         infer_dictionary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparquet_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sattu\\Desktop\\Projects\\nooblyForbes\\venv\\Lib\\site-packages\\pyarrow\\dataset.py:794\u001b[0m, in \u001b[0;36mdataset\u001b[1;34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[0m\n\u001b[0;32m    783\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    784\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m    785\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m     selector_ignore_prefixes\u001b[38;5;241m=\u001b[39mignore_prefixes\n\u001b[0;32m    791\u001b[0m )\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_path_like(source):\n\u001b[1;32m--> 794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_filesystem_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_path_like(elem) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, FileInfo) \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m source):\n",
      "File \u001b[1;32mc:\\Users\\sattu\\Desktop\\Projects\\nooblyForbes\\venv\\Lib\\site-packages\\pyarrow\\dataset.py:476\u001b[0m, in \u001b[0;36m_filesystem_dataset\u001b[1;34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[0m\n\u001b[0;32m    474\u001b[0m         fs, paths_or_selector \u001b[38;5;241m=\u001b[39m _ensure_multiple_sources(source, filesystem)\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 476\u001b[0m     fs, paths_or_selector \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_single_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m options \u001b[38;5;241m=\u001b[39m FileSystemFactoryOptions(\n\u001b[0;32m    479\u001b[0m     partitioning\u001b[38;5;241m=\u001b[39mpartitioning,\n\u001b[0;32m    480\u001b[0m     partition_base_dir\u001b[38;5;241m=\u001b[39mpartition_base_dir,\n\u001b[0;32m    481\u001b[0m     exclude_invalid_files\u001b[38;5;241m=\u001b[39mexclude_invalid_files,\n\u001b[0;32m    482\u001b[0m     selector_ignore_prefixes\u001b[38;5;241m=\u001b[39mselector_ignore_prefixes\n\u001b[0;32m    483\u001b[0m )\n\u001b[0;32m    484\u001b[0m factory \u001b[38;5;241m=\u001b[39m FileSystemDatasetFactory(fs, paths_or_selector, \u001b[38;5;28mformat\u001b[39m, options)\n",
      "File \u001b[1;32mc:\\Users\\sattu\\Desktop\\Projects\\nooblyForbes\\venv\\Lib\\site-packages\\pyarrow\\dataset.py:441\u001b[0m, in \u001b[0;36m_ensure_single_source\u001b[1;34m(path, filesystem)\u001b[0m\n\u001b[0;32m    439\u001b[0m     paths_or_selector \u001b[38;5;241m=\u001b[39m [path]\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(path)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filesystem, paths_or_selector\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: desiquant/data/news/LICI.parquet.gz"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"RELIANCE.csv\") # save to local disk\n",
    "\n",
    "for symbol in stock_symbols:\n",
    "    symbol_without_ns = symbol.replace(\".NS\", \"\")\n",
    "    uri = f\"s3://desiquant/data/news/{symbol_without_ns}.parquet.gz\"\n",
    "    df = pd.read_parquet(uri, storage_options=s3_params)\n",
    "    df.to_csv(f\"{symbol_without_ns}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
